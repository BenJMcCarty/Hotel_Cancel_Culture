{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Modeling - Regression\n",
    "\n",
    "---\n",
    "\n",
    "* Goal: to develop baseline models prior to feature engineering to compare performance vs. post-engineered models.\n",
    "\n",
    "My goal with this notebook is to develop a series of baseline models using minimal preprocessing. These models will establish a baseline performance for me to improve with additional feature engineering. Additionally, the most impactful features for each model can indicate if there are any features that are too strongly predictive.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sweetviz as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SKLearn and Modeling Tools\n",
    "\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.pipeline import Pipeline as fePipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, StandardScaler\n",
    "\n",
    "set_config(transform_output='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_feather('../../data/source/full_data.feather')\n",
    "# df_data = df_data.set_index('UUID')\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Target Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'ADR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv.analyze(df_data,pairwise_analysis = 'off').show_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Quick Overview: Review**\n",
    "\n",
    "Based on the quick EDA, I see there are both categorical features (several with high cardinality) and continuous (with right-tailed skews and some extreme outliers).\n",
    "\n",
    "**Questionable Features**\n",
    "\n",
    "First, I will drop the column `UUID` as it is a unique identifier and does not have any predictive value.\n",
    "\n",
    "There are two features that I can identify from domain knowledge as being too strongly predictive of the ADR (`IsCanceled`, `ReservationStatus`). These features indicate whether or not a guest stayed (if they cancel or no-show, the revenue is zero).\n",
    "\n",
    "Additionally, there are some temporal features that are either irrelevant to predictive modeling (`ArrivalDateYear`) or too closely related to the predictive features above (`ReservationStatusDate`).\n",
    "\n",
    "I will drop these features to match real-world data more closely/realistically.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.drop(columns = ['UUID', 'IsCanceled',\n",
    "                                  'ReservationStatus',\n",
    "                                  'ReservationStatusDate',\n",
    "                                  'ArrivalDateYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split and Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.drop(columns = target_feature)\n",
    "y = df_data[target_feature]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 903)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Feature-Engine Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = X.select_dtypes('object').columns\n",
    "num_feats = X.select_dtypes('number').columns\n",
    "\n",
    "cat_pipeline = fePipeline([('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "                           ('encoder', CountFrequencyEncoder(encoding_method = 'frequency',\n",
    "                                                             unseen = 'encode',\n",
    "                                                             missing_values = 'ignore'))])\n",
    "\n",
    "num_pipeline = fePipeline([('imputer', SimpleImputer(strategy='mean')),\n",
    "                           ('powertransformer', PowerTransformer(method = 'yeo-johnson')),\n",
    "                           ('scaler', StandardScaler())])\n",
    "\n",
    "## Combine transformers into a single ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_pipeline, num_feats),\n",
    "                                               ('cat', cat_pipeline, cat_feats)\n",
    "                                               ])\n",
    "\n",
    "## Define the target transformer\n",
    "target_transformer = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "## Instantiate the model\n",
    "base_regressor = RandomForestRegressor(n_jobs = -1,\n",
    "                                  random_state = 903,\n",
    "                                  min_samples_split = 2,\n",
    "                                  min_samples_leaf = 2)\n",
    "\n",
    "# Create the TransformedTargetRegressor with Yeo-Johnson transformation\n",
    "regressor = TransformedTargetRegressor(regressor=base_regressor, transformer=target_transformer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models with Feature-Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', regressor)\n",
    "])\n",
    "model_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = round(model_pipeline.score(X_train, y_train),4)\n",
    "\n",
    "test_score = round(model_pipeline.score(X_test, y_test), 4)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_pipeline.predict(X_test)\n",
    "\n",
    "mean_ae = metrics.mean_absolute_error(preds, y_test)\n",
    "median_ae = metrics.median_absolute_error(preds, y_test)\n",
    "\n",
    "print(f'The MAE is {mean_ae:,.2f} and the Median Absolute Error is {median_ae:,.2f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [tree.get_depth() for tree in model_pipeline[-1].regressor_.estimators_]\n",
    "\n",
    "sns.histplot(depths);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate permutation importances\n",
    "result = permutation_importance(model_pipeline,\n",
    "                                X_test, y_test,\n",
    "                                random_state=42,\n",
    "                                n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract importances and standard deviations\n",
    "perm_importances = result.importances_mean\n",
    "perm_importances_std = result.importances_std\n",
    "\n",
    "# Create a DataFrame for easy plotting\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': perm_importances,\n",
    "    'Importance_std': perm_importances_std\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "sns.barplot(x='Importance', y='Feature',data=importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('End of Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert NaN and Negative ADRs to .0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_target = pd.Series(np.where(df_data_target <= 0,.0001,df_data_target))\n",
    "df_data_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_target.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_test_bl_model(X_train, y_train,\n",
    "                             X_test, y_test,\n",
    "                             regressor,\n",
    "                             show_metrics = True):\n",
    "\n",
    "### ---  Creating ColumnTransformer and sub-transformers for imputation and encoding --- ###\n",
    "    num_cols = X_train.select_dtypes('number').columns\n",
    "    cat_cols = X_train.select_dtypes('object').columns\n",
    "    \n",
    "    cat_pipe = Pipeline(steps=[('cat_imp', SimpleImputer(strategy = 'most_frequent')),\n",
    "                               ('ohe',OneHotEncoder(drop = 'if_binary',\n",
    "                                              handle_unknown='ignore',\n",
    "                                              sparse_output=False))])\n",
    "    \n",
    "    num_pipe = Pipeline(steps=[('cat_imp', SimpleImputer(strategy = 'most_frequent')),\n",
    "                               ('scaler', StandardScaler())])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[('num', num_pipe, num_cols),\n",
    "                                                   ('cat', cat_pipe, cat_cols)])\n",
    "        \n",
    "    # Integrating the preprocessor with the regressor into a pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', regressor)])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    if show_metrics == True:\n",
    "        preds = pipeline.predict(X_test)\n",
    "        mae = metrics.mean_absolute_error(y_test, preds)\n",
    "        rmse = metrics.root_mean_squared_error(y_test, preds)\n",
    "        r2 = metrics.r2_score(y_test, preds)\n",
    "        \n",
    "        print(f'\\nThe MAE is: {mae:.2f}',\n",
    "              f'\\nThe RMSE is: {rmse:.2f}'\n",
    "              f'\\nThe R2 is: {r2:.2f}')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_test_bl_model(X_train,y_train, X_test, y_test, DummyRegressor(random_state = 903))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_and_test_bl_model(X_train,y_train, X_test, y_test,\n",
    "                         HistGradientBoostingRegressor(random_state = 903))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfr_model = create_and_test_bl_model(X_train,y_train, X_test, y_test, \n",
    "                                     RandomForestRegressor(n_jobs = -1,\n",
    "                                                           min_samples_split=2,\n",
    "                                                           max_depth=75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [tree.get_depth() for tree in rfr_model[-1].estimators_]\n",
    "\n",
    "sns.histplot(depths);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model[-1].feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### ---  Creating ColumnTransformer and sub-transformers for imputation and encoding --- ###\n",
    "# num_cols = X.select_dtypes('number').columns\n",
    "# cat_cols = X.select_dtypes('object').columns\n",
    "\n",
    "# cat_pipe = Pipeline(steps=[('cat_imp', SimpleImputer(strategy = 'most_frequent')),\n",
    "#                            ('ohe',\n",
    "#                             OneHotEncoder(drop = 'if_binary',\n",
    "#                                           handle_unknown='ignore',\n",
    "#                                           sparse_output=False))])\n",
    "\n",
    "# num_pipe = Pipeline(steps=[('cat_imp', SimpleImputer(strategy = 'most_frequent')),\n",
    "#                            ('scaler', StandardScaler())])\n",
    "\n",
    "# preprocessor = ColumnTransformer(transformers=[('num', num_pipe, num_cols),\n",
    "#                                                ('cat', cat_pipe, cat_cols)])\n",
    "\n",
    "# # Integrating the preprocessor with the SGDRegressor into a pipeline\n",
    "# pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                            ('regressor', SGDRegressor(loss='huber',\n",
    "#                                                       penalty='elasticnet',\n",
    "#                                                       random_state=903))])\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# preds = pipeline.predict(X_test)\n",
    "# mae = metrics.mean_absolute_error(y_test, preds)\n",
    "# rmse = metrics.root_mean_squared_error(y_test, preds)\n",
    "# r2 = metrics.r2_score(y_test, preds)\n",
    "\n",
    "# print(f'\\nThe MAE is: {mae:.2f}',\n",
    "#       f'\\nThe RMSE is: {rmse:.2f}'\n",
    "#       f'\\nThe R2 is: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                            ('regressor', XGBRegressor(objective='reg:squarederror', random_state=42))])\n",
    "\n",
    "# # Fit the pipeline to the training data\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "# mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "# r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "# # Print the results\n",
    "# print(f\"Mean Absolute Error (MAE): {mae:,.2f}\",)\n",
    "# print(f\"Mean Squared Error (MSE): {mse:,.2f}\",)\n",
    "# print(f\"R-squared (RÂ²): {r2:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The best model was the Random Forest Regressor model, with an MAE of # and R^2 of #. This model performed well with minor pre-processing, leading me to believe there may be features that are strongly predictive of the ADR. I will need to investigate further to confirm.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds-env)",
   "language": "python",
   "name": "ds-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
