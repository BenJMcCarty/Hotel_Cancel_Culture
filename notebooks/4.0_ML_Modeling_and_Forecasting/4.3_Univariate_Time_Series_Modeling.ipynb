{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¨ **Hotel Cancel Culture - Time Series Modeling & Forecasting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Forecasting Cancellations**\n",
    "\n",
    "> * **Goal:** Forecast cancellations for the given hotel data\n",
    "> * **Why:** Predictions only work on preexisting reservations\n",
    "    * *How can we forecast occupancy without depending on preexisting reservations?*\n",
    "> * **How:** Using probabilities generated from prior classification modeling to forecast future cancellations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:20:01.001505Z",
     "start_time": "2021-10-27T17:20:00.932506Z"
    }
   },
   "outputs": [],
   "source": [
    "## JNB tool to reload functions when called\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enabling access to custom functions in separate directory\n",
    "\n",
    "# Import necessary modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Construct the absolute path to the 'src' directory\n",
    "src_path = os.path.abspath(os.path.join('../..', 'src'))\n",
    "\n",
    "# Append the path to 'sys.path'\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# import db_utils, eda\n",
    "import time_series_modeling as tsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:20:05.952510Z",
     "start_time": "2021-10-27T17:20:01.003507Z"
    }
   },
   "outputs": [],
   "source": [
    "import holidays\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pmdarima as pmd\n",
    "from pmdarima.arima import AutoARIMA\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from pmdarima.preprocessing import BoxCoxEndogTransformer, FourierFeaturizer\n",
    "from pmdarima.pipeline import Pipeline\n",
    "import statsmodels.tsa.api as tsa\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reading Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Reading Data and Setting the Datetime Index**\n",
    "\n",
    "> I will import the data I cleaned and prepped in advance for my modeling processes.\n",
    ">\n",
    "> I created an `arrival_date` column during the prep process containing the arrival date as a datetime object. Using this feature, I will reset my index to enable the time series modeling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/column_groups.json') as file:\n",
    "    col_dict = json.load(file)\n",
    "\n",
    "col_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_cols = col_dict['booking_details']\n",
    "# temporal_cols = col_dict['new_temporal_features']\n",
    "\n",
    "# booking_cols.extend(temporal_cols)\n",
    "# usecols = set(booking_cols)\n",
    "# usecols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:20:06.598514Z",
     "start_time": "2021-10-27T17:20:06.113514Z"
    }
   },
   "outputs": [],
   "source": [
    "## Reading data and setting DT index\n",
    "path = '../../data/2.2_temporally_updated_data.feather'\n",
    "data = pd.read_feather(path, columns = ['ADR', 'ArrivalDate'])\n",
    "data = data.sort_values('ArrivalDate')\n",
    "data = data.set_index('ArrivalDate')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Resampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Resampling the Arrival Dates**\n",
    "\n",
    "> My dataset includes multiple reservations per day, which makes sense, but also impairs the modeling process.\n",
    ">\n",
    "> **I will resample the data as daily averages for the modeling and forecasting process.**\n",
    "* *Daily resampling* allows me to view the data for all reservations for a given day.\n",
    "* *Computing the average cancellations* provides a normalized value allowing for easy comparisons between dates (without having to consider other features, such as occupancy, demand, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:20:07.852513Z",
     "start_time": "2021-10-27T17:20:06.601515Z"
    }
   },
   "outputs": [],
   "source": [
    "## Resampling for a rolling average daily cancellations with a three-day window\n",
    "ts_avg = (data['ADR']\n",
    "          .resample('D')\n",
    "          .mean()\n",
    "          .rolling(window=3)\n",
    "          .mean()\n",
    "          .dropna()\n",
    "          .to_frame())\n",
    "\n",
    "display(ts_avg)\n",
    "ts_avg.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Exogenous Features - Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate a list of holidays for Portugal\n",
    "# portugal_holidays = holidays.PT(years=range(ts_avg.index.min().year, ts_avg.index.max().year + 1))\n",
    "# portugal_holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to DataFrame and Add Holiday Boolean Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Define a custom holiday function\n",
    "# def holiday(df, holidays):\n",
    "#     \"\"\"\n",
    "#     Determines if each date in the given DataFrame is a holiday in Portugal.\n",
    "\n",
    "#     Args:\n",
    "#         df (pandas.DataFrame): The DataFrame containing the dates to check.\n",
    "\n",
    "#     Returns:\n",
    "#         pandas.Series: A Series of 0s and 1s indicating whether each date is a holiday (1) or not (0).\n",
    "#     \"\"\"\n",
    "#     temp_df = df.index.astype('str')\n",
    "#     temp_df = temp_df.isin(holidays)\n",
    "#     temp_df = temp_df.astype(int)\n",
    "    \n",
    "#     return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_avg['Holiday'] = holiday(ts_avg, holidays=portugal_holidays)\n",
    "# ts_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split\n",
    "\n",
    "---\n",
    "\n",
    "I will split my data to reserve the last 90 days-worth of data for testing. In my experience, we usually focus on a short-term window for forecasting due to the increasing volatility as time goes on.\n",
    "\n",
    "Ideally, I would prefer to forecast for an entire year, but due to the short timeline of my source data, I would have little data to use to train the model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the target variable (ADR) and exogenous feature\n",
    "# adr = ts_avg['ADR']\n",
    "# exog = ts_avg[['Holiday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training and testing sets - updated to include exogenous features\n",
    "train, test = pmd.model_selection.train_test_split(ts_avg, test_size = 90)\n",
    "\n",
    "# train, test, train_exog, test_exog = train_test_split(adr, exog, test_size = 90)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "train.plot(ax=ax, label='train')\n",
    "test.plot(ax=ax, label='test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:20:09.852517Z",
     "start_time": "2021-10-27T17:20:08.830515Z"
    }
   },
   "outputs": [],
   "source": [
    "## Performing seasonal decomp to determine seasonality for modeling\n",
    "# decomp = tsa.seasonal_decompose(split_dict['train'].loc['01-2016':'06-2016'])\n",
    "decomp = tsa.seasonal_decompose(train, period = 7)\n",
    "decomp.seasonal.plot(figsize = (7,2));\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Seasonality**\n",
    "\n",
    "> Based on the results of the seasonal decomposition, I see there is a weekly seasonality (there are four peaks/valleys per month). This matches up with my expectation that there would be regular stay/cancel patterns based on the day of the week a reservation is due to arrive.\n",
    ">\n",
    "> Now that I determined the seasonality, I will use it as an argument in my workflow function (created from a prior time series modeling project).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline steps\n",
    "pipeline = Pipeline([\n",
    "    ('boxcox', BoxCoxEndogTransformer(lmbda2=1e-6)),\n",
    "    ('fourier', FourierFeaturizer(m=365.25, k=4)),  # Adjust m and k as needed\n",
    "    ('arima', AutoARIMA(seasonal=True, m=365, stepwise=True, suppress_warnings=True, trace=True))\n",
    "])\n",
    "\n",
    "# Fit the pipeline with exogenous variables\n",
    "pipeline.fit(train, scoring = 'mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast, conf_int = pipeline.predict(n_periods = len(test), return_conf_int=True)\n",
    "forecast_df = (pd.DataFrame({'Lower CI': conf_int[:,0],\n",
    "                             'Forecast':forecast,\n",
    "                            'Upper CI':conf_int[:,1]},\n",
    "                           index = test.index)\n",
    "               .round(2))\n",
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define custom function to evaluate forecast\n",
    "\n",
    "def evaluate_forecast(y_true, y_pred, print_output=True):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a forecast by comparing the true values with the predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true (array-like): The true values of the target variable.\n",
    "    - y_pred (array-like): The predicted values of the target variable.\n",
    "    - print_output (bool, optional): Whether to print the evaluation metrics. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    - results (dict): A dictionary containing the evaluation metrics.\n",
    "        - mse (float): Mean Squared Error.\n",
    "        - mae (float): Mean Absolute Error.\n",
    "        - MedAE (float): Median Absolute Error.\n",
    "        - mape(%) (float): Mean Absolute Percentage Error in percentage.\n",
    "\n",
    "    Example usage:\n",
    "    >>> y_true = [1, 2, 3, 4, 5]\n",
    "    >>> y_pred = [1.2, 2.3, 3.5, 4.1, 5.2]\n",
    "    >>> evaluate_forecast(y_true, y_pred)\n",
    "    MSE: 0.10\n",
    "    MAE: 0.18\n",
    "    MEDAE: 0.20\n",
    "    MAPE(%): 3.60\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    mse = metrics.mean_squared_error(y_true, y_pred).round(2)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred).round(2)\n",
    "    medae = metrics.median_absolute_error(y_true, y_pred).round(2)\n",
    "    mape = metrics.mean_absolute_percentage_error(y_true, y_pred).round(2)\n",
    "\n",
    "    results = {'mse': mse, 'mae': mae, 'MedAE': medae, 'mape(%)': mape * 100}\n",
    "    if print_output:\n",
    "        for metric, value in results.items():\n",
    "            print(f\"{metric.upper()}: {value:.2f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_forecast(test, forecast_df['Forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "train.plot(ax=ax, label='train')\n",
    "test.plot(ax=ax, label='test')\n",
    "forecast_df['Forecast'].plot(ax=ax, label='forecast')\n",
    "ax.fill_between(forecast_df.index, forecast_df['Lower CI'], forecast_df['Upper CI'], color='k', alpha=0.1)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels as sm\n",
    "# Predict the in-sample fitted values\n",
    "fitted_values = pipeline.predict_in_sample()\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = train - fitted_values\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(residuals, label='Residuals')\n",
    "plt.title('Residuals from ARIMA Model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot ACF and PACF of residuals\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 4))\n",
    "\n",
    "# ACF plot\n",
    "sm.graphics.tsaplots.plot_acf(residuals, lags=40, ax=ax[0])\n",
    "ax[0].set_title('ACF of Residuals')\n",
    "\n",
    "# PACF plot\n",
    "sm.graphics.tsaplots.plot_pacf(residuals, lags=40, ax=ax[1])\n",
    "ax[1].set_title('PACF of Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Full Workflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**I will use a functionalized workflow from my prior time series modeling work to perform my analysis and generate my forecast.**\n",
    ">\n",
    "> This function:\n",
    ">  * Splits the data at a threshold based on either a percentage or specific period (in this case, the past 90 days)\n",
    ">  * Performs SARIMA modeling via PMD's Auto-Arima to determine the optimal hyperparameters and Statsmodels's SARIMAX model for the forecasting.\n",
    ">  * Generates forecasted data and 95% confidence interval for the time period set in the train/test split step.\n",
    ">  * Saves the train/test split data; forecast and confidence interval data; and associated visualizations to a dictionary for review.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:20:33.379550Z",
     "start_time": "2021-10-27T17:20:09.855518Z"
    }
   },
   "outputs": [],
   "source": [
    "## Running the workflow\n",
    "# results = tsm.ts_modeling_workflow(ts_avg, threshold = -90, xlabel='Dates',\n",
    "#                                    ylabel = 'Cancellations (%)',\n",
    "#                                    title = 'Forecasted Cancellations', m=7,\n",
    "#                                    show_vis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:20:33.523552Z",
     "start_time": "2021-10-27T17:20:33.381550Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting the keys for the resulting dictionary\n",
    "# results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:20:33.683553Z",
     "start_time": "2021-10-27T17:20:33.525556Z"
    }
   },
   "outputs": [],
   "source": [
    "# ##Rounding forecast data to nearest whole numbers\n",
    "# results['forecasted_data'] = (results['forecasted_data']*100).round(0)\n",
    "# results['forecasted_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:20:33.825555Z",
     "start_time": "2021-10-27T17:20:33.686552Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Identifying average for the 90-day window\n",
    "# results['forecasted_data'].mean().round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Forecast Confidence Interval**\n",
    "\n",
    "> Based on my time series model, the hotels may expect an average of 35% daily cancellations over the next 90 days. However, there is a confidence interval of  +/- 23.5%.\n",
    ">\n",
    "> **This large confidence interval limits the usefulness of the forecast due to the risk of errors.** If a hotel would overbook with the expectation of the average 35% cancellation rate, only to have a 45%+ cancellation rate, it would force the hotel to relocate a large number of reservations. As relocated reservations incur significant costs (both for paying for the relocated night as well as potentially losing future business), the risk of overbooking is too great with this model's forecast.\n",
    "\n",
    "**Reducing Risk**\n",
    "\n",
    "> The next step of this analysis would be adjusting the model to reduce variability of the forecast results. The adjustments may include:\n",
    " * Adding additional data (holidays, presence/absence of additional demand generators)\n",
    " * Adjusting threshold values for train/test split\n",
    "\n",
    "**Looking Forward**\n",
    "\n",
    "> My next steps will be to evaluate the impact of shorter- and longer-term thresholds for my training data. Initially, I started with a 90-day evaluation; I will reevaluate the performance using several different thresholds to compare the impact of using different windows for forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:24:05.928870Z",
     "start_time": "2021-10-27T17:20:33.827554Z"
    }
   },
   "outputs": [],
   "source": [
    "## Testing new thresholds for train/test split and forecast\n",
    "\n",
    "thresholds = [-3, -7, -15, -30, -60, -90, -180]\n",
    "\n",
    "ints = {}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    results = tsm.ts_modeling_workflow(ts_avg, threshold = threshold, xlabel='Dates',\n",
    "                                       ylabel = 'Cancellations (%)',\n",
    "                                       title = 'Forecasted Cancellations',\n",
    "                                       m=7,show_vis=False)\n",
    "    \n",
    "    ints[threshold*-1] = [round(results['forecasted_data']['Lower CI'].mean(), 2)*100,\n",
    "                  round(results['forecasted_data']['Forecast'].mean(), 2)*100,\n",
    "                  round(results['forecasted_data']['Upper CI'].mean(), 2)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:24:06.252870Z",
     "start_time": "2021-10-27T17:24:05.931873Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Combining results into DataFrame for analysis and display\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(ints, orient = 'index')\n",
    "results_df.rename(columns = {0: 'Lower CI', 1: 'Average', 2:'Upper CI'},\n",
    "                 inplace=True)\n",
    "\n",
    "results_df['CI Difference'] = (results_df['Upper CI'] - results_df['Lower CI'])\n",
    "\n",
    "results_df.index.rename('Days Out', inplace=True)\n",
    "\n",
    "results_df.style.background_gradient(subset = 'CI Difference', cmap='Reds')\\\n",
    "                                                            .format('{:.0f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Interval Impacts**\n",
    "\n",
    "> Despite changing the threshold levels, there is little improvement in the confidence intervals.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Results and Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "---\n",
    "\n",
    "**Best Performance:** 3/7/15 day windows\n",
    "  * Guests are less likely to cancel based on prior classification modeling\n",
    "  * Confidence intervals slightly smaller than longer-term perspective.\n",
    "  \n",
    "**Worst Performance:** 180+ days\n",
    "  * Strongest likelihood of cancellations based on prior models\n",
    "  * Limited benefits for on-site teams\n",
    "    * Sales may use it for longer-term planning, such as business account performances or group booking trends\n",
    "    * Operations may use it to identify potential spikes in occupancy/demand, guiding staffing decisions or intensive projects (such as deep cleaning, system updates, or renovations)\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "**In my opinion, the best results came from using a 90-day threshold to forecast cancellations.**\n",
    "\n",
    "> * **Short forecasts best for Operations:** creating schedules; ordering supplies; other time-sensitive decisions.\n",
    ">  * *Limited benefit for Sales due to short window of opportunity to book groups or push business travel.*\n",
    ">\n",
    ">\n",
    "> * **Longer Forecasts best for Sales:** booking groups and monitoring pickup; performing sales calls for targeted businesses.\n",
    ">  * *Less beneficial for Operations - scheduling, purchasing supplies based on occupancy and demand.*\n",
    "\n",
    "**Pros and Cons Based on Personal Experience/Opinions**\n",
    "\n",
    "| Time Period (Days) | Pros | Cons | Best Use |\n",
    "| --- | --- | --- | --- |\n",
    "| 3, 7, 15 | Increased accuracy | Less reaction time | Operations-related decision making; scheduling |\n",
    "| 30, 60, 90 | Actionable time window for Sales (group sales especially) | Less accurate; more of a \"rough idea\" | On-Site Sales & Marketing strategy |\n",
    "| 180+ | Can identify problem areas; trends/events; and focus areas | Numbers can and will change based on bookings/cancellations | Long-term revenue management\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caveats\n",
    "---\n",
    "\n",
    "***These results may not generalize well for other hotels and/or different times.***\n",
    "\n",
    "They are meant to be guidelines and ideas for hotels to adapt to their needs. These results are specific to these two hotels for this given time period.\n",
    "\n",
    "Each hotel is different: target clientele, amenities, locations, etc.. Additionally, larger market trends and events (locally or globally) may have positive and/or negative impacts on cancellations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "\n",
    "---\n",
    "\n",
    "**Future work includes:**\n",
    "\n",
    "* Multivariate time series modeling via variable autoregression (VAR)\n",
    "\n",
    "\n",
    "* Specific breakdowns:\n",
    "    * Guest type: transient, leisure, groups\n",
    "    * Room type: several different room types\n",
    "    * Hotel type: resort vs. city hotels\n",
    "\n",
    "\n",
    "* Model deployment for hotel-specific results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Thank you for your interest in my work.**\n",
    "\n",
    "This concludes my exploration of the hotel booking dataset via univariate time series analysis.\n",
    "\n",
    "While the results are not as exact as I would prefer, I feel confident in their current state and look forward to performing additional analysis via multivariate time series modeling as well as model deployment.\n",
    "\n",
    "**I welcome any comments or questions! Please feel free to contact me.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds-env)",
   "language": "python",
   "name": "ds-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
